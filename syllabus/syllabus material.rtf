{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf360
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww12240\viewh15840\viewkind1
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\ql\qnatural\pardirnatural

\f0\fs24 \cf0 ADDITIONAL MATERIAL FOR LEC 5: describe how gradient descent describes Newton etc, then describe how gradient can be time-consuming to compute in deep learning, then describe how using stochastic realizations of the gradient can be much faster (using Robbins-Munro 1951)\
\
Combine Tom's Lecs 12 and 13 into a new L12\
\

\b \ul MIDTERM
\b0 \ulnone \
\
CHAP 7: TOM'S LECS 16 - 20\
\
ADDITIONAL LECTURE AFTER CHAP 7:\
Applications where linear systems need to be solved:\
Solomon \
4.1.3 Tikhonov Regularization (other discussions of regularization: Numerical Recipes (inverse theory), Boyd p305; Abu-Mostafa L12))\
4.1.4 Image Alignment \
4.1.5 Deconvolution \

\b \ul \

\b0 \ulnone CHAP 9: TOM'S LEC 21 AND ONWARDS
\b \ul \
\

\b0 \ulnone ADDITIONAL MATERIAL FOR First EIGENVALUE LEC: \
MOTIVATION Solomon p125:\
6.1.1 Statistics \
6.1.2 Dierential Equations \
6.1.3 Spectral Embedding \
\
ADDITIONAL MATERIAL FOR POWER METHOD LEC: \
applications of power method PAGERANK:\
https://en.wikipedia.org/wiki/Power_iteration#Applications\
\
ADDITIONAL Material for SVD lecs:\
show how SVD can be used to\
* do data compression, data visualization (PCA); see NG exercise week 8\
* find low-rank matrix approximation to a data matrix, ie to find the most concise feature representation of users and items (Week 9 of NG course)\
7.2 APPLICATIONS OF THE SVD Solomon p152\
\
* 
\b CLRS ???
\b0 \
}